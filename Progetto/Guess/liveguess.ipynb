{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e892319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1 style=\"color:red; font-size:70px;\"> FeelNet live </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2af50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "\n",
    "mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d14a98",
   "metadata": {},
   "source": [
    "## Stesso thread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44213894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 18:39:20.530278: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920ms/step\n",
      "Predizione: neutral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
      "Predizione: neutral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n",
      "Predizione: neutral\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "Predizione: sad\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
      "Predizione: happy\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
      "Predizione: fear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "Predizione: fear\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "Predizione: neutral\n"
     ]
    }
   ],
   "source": [
    "# Faccio reloading del mio modello\n",
    "model = load_model(\"Modelli/dropoutTry.keras\")  \n",
    "\n",
    "# Inizio la cattura video. Il parametro specificato nella funzione VideoCapture è 0 \n",
    "# perchè vogliamo che la sorgente delle immagini sia la videocamera del computer\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "start = time.perf_counter()\n",
    "lastPred = start\n",
    "# Continuo a leggere le immagini e sulle stesse effettuo le dovute analisi, come per \n",
    "# esempio la riduzione al formato di nostro interesse (48 pixels x 48 pixels)  \n",
    "while time.perf_counter() - start <= 20:\n",
    "    # Inizio a leggere lo stream frame by frame utilizzando .read() di openCV. Tale funzione \n",
    "    # restituisce un bool (True se la lettura dell'immagine è andata a buon fine, False altrimenti)\n",
    "    # ed il frame in questione (che sarà quello su cui andremo ad agire).\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Ogni mezzo secondo faccio post-processing, con anche stampa dell'immagine stessa\n",
    "    if time.perf_counter() - lastPred > 0.5 or lastPred == start:\n",
    "        # Check su lettura adeguata o meno del frame\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame. Exiting ...\")\n",
    "            break\n",
    "\n",
    "        # Di seguito riportiamo l'immagine catturata nel formato richiesto come input dalla \n",
    "        # rete neurale. In farticolare con cv.cvtColor la riproponiamo in scala di grigi, \n",
    "        # mentre con i due passaggi successivi selezioniamo solamente la regione centrale \n",
    "        # del frame, per poi farne un resize\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        gray = gray[80:400, 160:480]\n",
    "        gray = cv.resize(gray, (48, 48))\n",
    "\n",
    "        # Provo a fare la guess. Dato che è necessario del tempo tecnico per far sì che la \n",
    "        # rete effettui la predizione, decidiamo di provarci ogni 0.5 secondi, in modo da non\n",
    "        # rallentare eccessivamente la visualizzazione\n",
    "        cls = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "        pred = model.predict(np.expand_dims(gray, axis=0))\n",
    "        lastPred = time.perf_counter()\n",
    "        print(\"Predizione: \" + cls[np.argmax(pred)])\n",
    "\n",
    "        # Mostriamo ora il frame a video. Per far sì che l'immagine sia visualizzata con una dimensione\n",
    "        # adeguata, definiamo una finestra della quale specifichiamo la dimensione\n",
    "        cv.namedWindow('frame', cv.WINDOW_NORMAL)\n",
    "        cv.resizeWindow('frame', 400, 300)\n",
    "        cv.imshow('frame', gray)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
