{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ece4ae",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1 style=\"color:red; font-size:70px;\"> Esercitazione 8</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a405fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras import layers, activations\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Rescaling, MaxPooling2D, Conv2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878f2e8",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; font-size:50px;\"> Esercizio 1 - Data augmentation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'obiettivo di questo esercizio è vedere in azione la tecnica del \"data augmentation\", che consente di aumentare artificialmente la quantità di dati disponibili per l'addestramento di un modello, senza che debbano essere raccolti nuovi dati reali. Questo consente di migliorare la performance del modello ed allo stesso tempo di ridurre il rischio di overfitting (in quanto è più difficile che il modello impari troppo bene i dati d'addestramento). Nel campo delle immagini solitamente per aumentare la dimensione del campione si fa uso di:\n",
    "\n",
    "- rotazioni\n",
    "\n",
    "- riflessioni\n",
    "\n",
    "- zoom o ritagli\n",
    "\n",
    "- variazioni di luminosità o contrasto\n",
    "\n",
    "- traslazioni\n",
    "\n",
    "- aggiunta di rumore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858aa9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
      "\u001b[1m228813984/228813984\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Come primo step per la risoluzione dell'esercizio importo il dataset sul quale vogliamo allenare una \n",
    "# rete neurale pensata per risolvere un problema di classificazione. Nello specifico sono 3670 immagini \n",
    "# di fiori, ciascuna delle quali è un tensore tridimensionale di (180, 180, 3) pixel\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
