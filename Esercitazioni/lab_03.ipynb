{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ea1c06",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1 style=\"color:red; font-size:70px;\"> Esercitazione 3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d4812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 14:17:14.051558: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-23 14:17:14.057363: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-23 14:17:14.077380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750681034.142719    9204 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750681034.153642    9204 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750681034.185780    9204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750681034.185830    9204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750681034.185835    9204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750681034.185838    9204 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-23 14:17:14.207046: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35453761",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; font-size:50px;\"> Esercizio 1 - MLP Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un Multilayer Perceptron (MLP) è un feedforward neural network caratterizzata da più strati di nodi interconnessi (neuroni), tra cui uno strato di input, uno o più strati nascosti e uno strato di output.\n",
    "\n",
    "<center>\n",
    "\n",
    "![MLP](Immagini/Teoria/MLP.png)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386af97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input della rete neurale: \n",
      " [[-1.        ]\n",
      " [-0.7777778 ]\n",
      " [-0.5555556 ]\n",
      " [-0.33333334]\n",
      " [-0.11111111]\n",
      " [ 0.11111111]\n",
      " [ 0.33333334]\n",
      " [ 0.5555556 ]\n",
      " [ 0.7777778 ]\n",
      " [ 1.        ]]\n",
      "\n",
      "\n",
      "Output della rete neurale:  tf.Tensor(\n",
      "[[-1.2428458]\n",
      " [-1.2515835]\n",
      " [-1.2627645]\n",
      " [-1.2766579]\n",
      " [-1.292205 ]\n",
      " [-1.3070393]\n",
      " [-1.3190391]\n",
      " [-1.327625 ]\n",
      " [-1.3334216]\n",
      " [-1.3373427]], shape=(10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Richiedo dimensione dei layer della rete da inizializzare\n",
    "nin = int(input(\"Dimensione strato di input: \"))\n",
    "nhid1 = int(input(\"Dimensione primo strato nascosto: \"))\n",
    "nhid2 = int(input(\"Dimensione secondo strato nascosto: \"))\n",
    "nout = int(input(\"Dimensione strato di output: \"))\n",
    "\n",
    "\n",
    "# Allocazione pesi e bias per i vari neuroni, sui quali verrà fatto l'addestramento della rete\n",
    "# Tutte queste quantità devono essere delle variabili, perchè vanno cambiate in addestramento\n",
    "# Dato che ad ogni connessione fra neuroni va assegnato un peso diverso, le quantità incluse nel\n",
    "# primo dizionario sono delle matrici con un numero di righe pari ai neuroni \"di partenza\" ed un \n",
    "# numero di colonne pari a quello dei neuroni \"d'arrivo\". Questo perchè: y = x*W + b, ossia il \n",
    "# prodotto matriciale viene fatto al contrario. I bias sono invece vettori con lunghezza pari al numero\n",
    "# di nodi dello strato a cui si riferiscono. Per creare tensori casuali utilizzo il metodo tf.random.normal\n",
    "# che consente di generare un set di dati gaussiani la cui forma è uno dei parametri da specificare\n",
    "pesi = {\n",
    "    'hid1': tf.Variable(tf.random.normal([nin, nhid1])), \n",
    "    'hid2': tf.Variable(tf.random.normal([nhid1, nhid2])), \n",
    "    'out': tf.Variable(tf.random.normal([nhid2, nout]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hid1': tf.Variable(tf.random.normal([nhid1])),\n",
    "    'hid2': tf.Variable(tf.random.normal([nhid2])),\n",
    "    'out': tf.Variable(tf.random.normal([nout]))\n",
    "}\n",
    "\n",
    "\n",
    "# Funzione che prende input e fornisce come risultato l'output della rete neurale\n",
    "# Vogliamo in definiva fare in modo esplicito i conti che portano alla produzione dell'output, \n",
    "# Per compiere le operazioni utilizzo delle funzioni della libreria tensorflow ed in particolare:\n",
    "#\n",
    "#   - matmul(a, b) --> consente di fare moltiplicazioni matriciali\n",
    "#   - add(a, b) --> consente di sommare fra loro tensori\n",
    "#\n",
    "# Questo serve ad ogni step per capire dove valutare la funzione d'attivazione. In questo caso \n",
    "# vogliamo una sigmoide sui layer nascosti ed invece un comportamento lineare per l'output\n",
    "def modMPL(indat):\n",
    "    appo = tf.sigmoid(tf.add(tf.matmul(indat, pesi[\"hid1\"]), bias[\"hid1\"]))\n",
    "    appo = tf.sigmoid(tf.add(tf.matmul(appo, pesi[\"hid2\"]), bias[\"hid2\"]))\n",
    "    appo = tf.add(tf.matmul(appo, pesi[\"out\"]), bias[\"out\"])\n",
    "    return appo\n",
    "\n",
    "\n",
    "# Valutiamo output del modello per 10 valori equispaziati fra -1 ed 1\n",
    "test = np.linspace(-1, 1, 10, dtype = np.float32)\n",
    "print(\"Input della rete neurale: \\n\", test.reshape(-1, 1))\n",
    "print(\"\\n\\nOutput della rete neurale: \", modMPL(test.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f048f1",
   "metadata": {},
   "source": [
    "<h1 style=\"color: blue; font-size:50px;\"> Esercizio 2 - Sequential model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'obiettivo di questo esercizio è tradurre l'esercizio precedente utilizzando le funzionalità sequenziali di TensorFlow/Keras. Un **modello sequenziale*** è appropriato per descrivere un sistema costituito da una serie di layers dei quali ciascuno presenta rispettivamente un solo tensore di input ed un solo tensore di output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82ea5781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hid1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hid2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hid1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m5\u001b[0m)                │            \u001b[38;5;34m10\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ hid2 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2\u001b[0m)                │            \u001b[38;5;34m12\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ out (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (100.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25\u001b[0m (100.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> (100.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25\u001b[0m (100.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le due reti neurali producono lo stesso output!\n",
      "\n",
      "\n",
      "Pesi del modello: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Variable path=sequential_16/hid1/kernel, shape=(1, 5), dtype=float32, value=[[-0.49099052  0.592398   -0.77512896 -0.6804413  -0.33347145]]>,\n",
       " <Variable path=sequential_16/hid1/bias, shape=(5,), dtype=float32, value=[-0.3849648  -0.05356302 -0.6304463   0.46109116 -1.1896571 ]>,\n",
       " <Variable path=sequential_16/hid2/kernel, shape=(5, 2), dtype=float32, value=[[-0.43022877  0.418887  ]\n",
       "  [ 0.00744309 -0.14922425]\n",
       "  [ 0.00177292 -0.02002541]\n",
       "  [ 0.50097203 -1.6511942 ]\n",
       "  [ 0.8370611  -0.19532157]]>,\n",
       " <Variable path=sequential_16/hid2/bias, shape=(2,), dtype=float32, value=[-0.46822706  0.73423445]>,\n",
       " <Variable path=sequential_16/out/kernel, shape=(2, 1), dtype=float32, value=[[-0.7369044]\n",
       "  [ 1.3589365]]>,\n",
       " <Variable path=sequential_16/out/bias, shape=(1,), dtype=float32, value=[-0.660612]>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Richiedo dimensione dei layer della rete da inizializzare\n",
    "nin = int(input(\"Dimensione strato di input: \"))\n",
    "nhid1 = int(input(\"Dimensione primo strato nascosto: \"))\n",
    "nhid2 = int(input(\"Dimensione secondo strato nascosto: \"))\n",
    "nout = int(input(\"Dimensione strato di output: \"))\n",
    "\n",
    "\n",
    "# Definisco il modello sequenziale e le tipologie di layers (quelli nascosti hanno come funzione d'attivazione\n",
    "# dei sigmoidi, mentre il layer di output deve essere lineare). Come argomento di keras.Sequential dobbiamo \n",
    "# specificare i piani di nodi che vogliamo connettere fra loro. In questo caso scelgo dei layer Dense, ossia \n",
    "# fully connected, e per ciascuno di questi indico quanti siano i nodi costituenti, la funzione d'attivazione e \n",
    "# il nome del piano. Se non viene specificato alcun argomento per activation, il comportamento dei nodi sarà lineare.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(nhid1, activation = \"sigmoid\", name = \"hid1\"), \n",
    "        layers.Dense(nhid2, activation = \"sigmoid\", name = \"hid2\"), \n",
    "        layers.Dense(nout, name = \"out\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Riporto l'implementazione del vecchio modello per verificare che le capacità predittive dei due\n",
    "# siano in accordo fra loro (e che quindi siano effettivamente uno la traduzione dell'altro)\n",
    "pesi = {\n",
    "    'hid1': tf.Variable(tf.random.normal([nin, nhid1])), \n",
    "    'hid2': tf.Variable(tf.random.normal([nhid1, nhid2])), \n",
    "    'out': tf.Variable(tf.random.normal([nhid2, nout]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hid1': tf.Variable(tf.random.normal([nhid1])),\n",
    "    'hid2': tf.Variable(tf.random.normal([nhid2])),\n",
    "    'out': tf.Variable(tf.random.normal([nout]))\n",
    "}\n",
    "\n",
    "def modMPL(indat):\n",
    "    appo = tf.sigmoid(tf.add(tf.matmul(indat, pesi[\"hid1\"]), bias[\"hid1\"]))\n",
    "    appo = tf.sigmoid(tf.add(tf.matmul(appo, pesi[\"hid2\"]), bias[\"hid2\"]))\n",
    "    appo = tf.add(tf.matmul(appo, pesi[\"out\"]), bias[\"out\"])\n",
    "    return appo\n",
    "\n",
    "# Stampo a video il riassunto del modello, che consente di valutarne l'architettura\n",
    "# Per stampare è necessario provare il modello su un input standard\n",
    "x = tf.ones((10, 1))\n",
    "y = model(x)\n",
    "model.summary()\n",
    "\n",
    "# Verifico le capacità predeittive dei due modelli usando come input 10 valori equispaziati fra -1 ed 1\n",
    "# Per vedere se il modello ha le stesse caratteristiche di quello precedente assegnamo gli stessi pesi e \n",
    "# gli stessi bias. Per fare questo utilizziamo la funzione set_weights, che fissa il valore dei pesi a partire \n",
    "# da una lista di array numpy (bisogna specificare sia il peso, che il bias). Il confronto fra output lo faccio \n",
    "# in modo automatico, ossia usando la funzione allclose\n",
    "test = np.linspace(-1, 1, 10, dtype = np.float32).reshape(-1, 1)\n",
    "model.set_weights(\n",
    "    [\n",
    "        pesi[\"hid1\"], bias[\"hid1\"],\n",
    "        pesi[\"hid2\"], bias[\"hid2\"],\n",
    "        pesi[\"out\"], bias[\"out\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "outMLP = modMPL(test)\n",
    "outSeq = model(test)\n",
    "\n",
    "if not np.allclose(outMLP, outSeq):\n",
    "    print(\"Output discrepanti! Errore in costruzione delle reti neurali!\")\n",
    "    print(\"\\nOutput vecchio modello: \", outMLP)\n",
    "    print(\"\\nOutput modello sequenziale: \", outSeq)\n",
    "\n",
    "else:\n",
    "    print(\"Le due reti neurali producono lo stesso output!\")\n",
    "\n",
    "\n",
    "# Stampo i pesi del modello (che sono uguali sia per quello con moltiplicazioni matrciali \n",
    "# esplicite, che per quello che usa gli strumenti di keras) utilizzando la flag .weights\n",
    "print(\"\\n\\nPesi del modello: \")\n",
    "model.weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
