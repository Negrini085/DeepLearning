{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffbe0ed",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1 style=\"color:red; font-size:70px;\"> Simple CNN</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a33de3",
   "metadata": {},
   "source": [
    "In questo jupiter notebook è presente un semplice esempio di CNN classifier, il cui obiettivo è quello di riconoscere se le radiografie polmonari di alcuni pazienti evidenziano l'infezione da COVID-19 oppure no. Il dataset in uso è stato scaricato da Kaggle al seguente link: https://www.kaggle.com/datasets/khoongweihao/covid19-xray-dataset-train-test-sets?resource=download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa80ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Rescaling, MaxPooling2D, Conv2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02097f7a",
   "metadata": {},
   "source": [
    "## Costruzione del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f914d4",
   "metadata": {},
   "source": [
    "In questo spezzone di codice viene preparato il dataset di immagini perché possa essere utilizzato in maniera semplice da una rete neurale convoluzionale. Per prima cosa viene specificato dove si trovano i le immagini; viene fornito solo il nome della cartella madre, perchè le sottocartelel saranno interpretate come le varie classi. Una volta normalizzati i valori dei pixels, si utilizza la funzione ***flow_from_directory*** per leggere le immagini e ridimensionarle alla size desiderata. Inoltre, dato che viene specificata una batch size di 32, le immagini non vengono caricate tutte insieme in memoria, ma elaborate a piccoli gruppi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbc86a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4505 images belonging to 4 classes.\n",
      "Found 1126 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Raccoglie le varie classi, che avranno come nome quello delle sotto-cartelle\n",
    "dataset_dir = \"Datasets/satellite\"  \n",
    "\n",
    "# Generatore con split per validation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  \n",
    ")\n",
    "\n",
    "# Dataset di training\n",
    "trDat = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Dataset di validation\n",
    "valDat = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3436ee3",
   "metadata": {},
   "source": [
    "## Costruzione del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reti neurali convoluzionali (CNN, Convolutional Neural Networks) prendono il loro nome dal fatto che il loro elemento fondamentale è l’operazione di convoluzione. In altre parole, invece di collegare ogni neurone a tutti i pixel di un’immagine come nelle reti dense tradizionali, le CNN applicano filtri (kernel) piccoli che scorrono sull’immagine per rilevare caratteristiche locali come bordi, angoli, texture o pattern specifici.\n",
    "\n",
    "Questa logica è proprio quella implementata nella funzione ***buildMod***, il cui obiettivo è quello di restituire un modello che consenta un'analisi accurata delle immagini con conseguente classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50cccb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 18:58:14.444344: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Funzione per costruire il modello in questione\n",
    "def builMod(imH, imW, numcl):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Input(shape=(imH, imW, 3)))\n",
    "    # Per i layer convoluzionali utilizzaimo Conv2D, che crea un kernel convoluzionale che è in \n",
    "    # convoluzione con l'input su uno spazio 2D (larghezza e lunghezza). In particolare specifichiamo:\n",
    "    #\n",
    "    # filters --> il numero di filtri da applicare. Ogni filtro si dedica all'individuazione di \n",
    "    # una caratteristica differente, quindi \"più filtri == più caratteristiche \n",
    "    # imparate\"\n",
    "    #\n",
    "    # kernel_size --> specifica le dimensioni del filtro, quindi larghezza ed altezza\n",
    "    #\n",
    "    # Si possono anche specificare altri parametri quali la funzione d'attivazione\n",
    "    model.add(Conv2D(16, (3, 3), activation = 'relu'))\n",
    "    # Dopo uno strato convozionale introduciamo un layer di pooling, il cui scopo è quello di \n",
    "    # rendere più efficiente la rete neurale, dato che la dimensione delle immagini vinee ridotta, \n",
    "    # mantenendo tuttavia le caratteristiche principali. Questo vuol dire che le successive analisi \n",
    "    # saranno più immmediate. Un parametro importante da segnalare è il \"pool_size\", che definisce \n",
    "    # le dimensioni della finestra di campionamento\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Per rendere lo studio dell'immagine più accurato inserisco altri layer convoluzionali e di \n",
    "    # pooling, in modo da caratterizzare altre features\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "    # Inizia ora la parte fully connected per la classificazione delle immagini\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(numcl, activation = 'softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Costruzione del modello ed allenamento della rete\n",
    "model = builMod(32, 32, 10)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
